{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2958.41257,
      "end_time": "2023-10-11T19:48:42.630135",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-10-11T18:59:24.217565",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download and import libraries"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.005994,
          "end_time": "2023-10-11T18:59:32.701909",
          "exception": false,
          "start_time": "2023-10-11T18:59:32.695915",
          "status": "completed"
        },
        "tags": [],
        "id": "VQaXBAKHIVe4"
      },
      "id": "VQaXBAKHIVe4"
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -c conda-forge spacy -y\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "papermill": {
          "duration": 81.91837,
          "end_time": "2023-10-11T19:00:54.626111",
          "exception": false,
          "start_time": "2023-10-11T18:59:32.707741",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_5ydTsjIVe5",
        "outputId": "ff4e295f-11bd-411e-f948-7780d5b3ae39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "id": "U_5ydTsjIVe5"
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required libraries\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math,copy,re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import gc\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:00:54.649324Z",
          "iopub.status.busy": "2023-10-11T19:00:54.648766Z",
          "iopub.status.idle": "2023-10-11T19:00:56.926502Z",
          "shell.execute_reply": "2023-10-11T19:00:56.925461Z"
        },
        "papermill": {
          "duration": 2.291735,
          "end_time": "2023-10-11T19:00:56.928467",
          "exception": false,
          "start_time": "2023-10-11T19:00:54.636732",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbRU00AwIVe6",
        "outputId": "6701b6f5-8a8e-4556-9dc2-3a45e2756de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n"
          ]
        }
      ],
      "id": "vbRU00AwIVe6"
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic=True\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:00:56.951863Z",
          "iopub.status.busy": "2023-10-11T19:00:56.950773Z",
          "iopub.status.idle": "2023-10-11T19:00:56.958375Z",
          "shell.execute_reply": "2023-10-11T19:00:56.957611Z"
        },
        "papermill": {
          "duration": 0.020651,
          "end_time": "2023-10-11T19:00:56.960060",
          "exception": false,
          "start_time": "2023-10-11T19:00:56.939409",
          "status": "completed"
        },
        "tags": [],
        "id": "6QhMzL9VIVe7"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6QhMzL9VIVe7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Model (based on Attention is All you Need, Vaswani et. al.)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.010268,
          "end_time": "2023-10-11T19:00:56.980656",
          "exception": false,
          "start_time": "2023-10-11T19:00:56.970388",
          "status": "completed"
        },
        "tags": [],
        "id": "tZik61-gIVe7"
      },
      "id": "tZik61-gIVe7"
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.embed_layer = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.embed_layer(x)\n",
        "        return out\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:00:57.002802Z",
          "iopub.status.busy": "2023-10-11T19:00:57.002018Z",
          "iopub.status.idle": "2023-10-11T19:00:57.007422Z",
          "shell.execute_reply": "2023-10-11T19:00:57.006690Z"
        },
        "papermill": {
          "duration": 0.018126,
          "end_time": "2023-10-11T19:00:57.009132",
          "exception": false,
          "start_time": "2023-10-11T19:00:56.991006",
          "status": "completed"
        },
        "tags": [],
        "id": "QYu3RvEiIVe7"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QYu3RvEiIVe7"
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, max_seq_len, embed_dim):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        pe = torch.zeros((self.max_seq_len, self.embed_dim))\n",
        "\n",
        "        for pos in range(self.max_seq_len):\n",
        "            for i in range(0, self.embed_dim, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000**(i/self.embed_dim)))\n",
        "                pe[pos, i+1] = math.cos(pos / (10000**(i/self.embed_dim)))\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, inp):\n",
        "        inp = inp*math.sqrt(self.embed_dim)\n",
        "        seq_len = inp.size(1)\n",
        "        inp = inp + torch.autograd.Variable(self.pe[:, :seq_len], requires_grad=False)\n",
        "        return inp"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:00:57.030702Z",
          "iopub.status.busy": "2023-10-11T19:00:57.030465Z",
          "iopub.status.idle": "2023-10-11T19:00:57.036506Z",
          "shell.execute_reply": "2023-10-11T19:00:57.035627Z"
        },
        "papermill": {
          "duration": 0.01892,
          "end_time": "2023-10-11T19:00:57.038177",
          "exception": false,
          "start_time": "2023-10-11T19:00:57.019257",
          "status": "completed"
        },
        "tags": [],
        "id": "REiUxPtUIVe7"
      },
      "execution_count": null,
      "outputs": [],
      "id": "REiUxPtUIVe7"
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, embed_dim=512, n_heads=8):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        self.head_dim = int(self.embed_dim/self.n_heads)\n",
        "\n",
        "        self.query_matrix = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.key_matrix = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "        self.value_matrix = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
        "\n",
        "        self.out = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "\n",
        "    def forward(self, key, query, value, mask=None):\n",
        "        batch_size = key.size(0)\n",
        "        seq_len = key.size(1)\n",
        "\n",
        "        seq_len_query = query.size(1)\n",
        "\n",
        "        key = key.view(batch_size, seq_len, self.n_heads, self.head_dim)\n",
        "        query = query.view(batch_size, seq_len_query, self.n_heads, self.head_dim)\n",
        "        value = value.view(batch_size, seq_len, self.n_heads, self.head_dim)\n",
        "\n",
        "        k = self.key_matrix(key)\n",
        "        q = self.query_matrix(query)\n",
        "        v = self.value_matrix(value)\n",
        "\n",
        "        k = k.transpose(1,2)\n",
        "        q = q.transpose(1,2)\n",
        "        v = v.transpose(1,2)\n",
        "\n",
        "        k_adj = k.transpose(-1,-2)\n",
        "\n",
        "        # prdt = torch.einsum(\"bhqd,bhdk->bhqk\", q, k_adj)\n",
        "        prdt = torch.matmul(q, k_adj)\n",
        "\n",
        "        if mask is not None:\n",
        "            prdt = prdt.masked_fill(mask==0, float(\"-1e20\"))\n",
        "\n",
        "        prdt = prdt/math.sqrt(self.embed_dim)\n",
        "        prdt = F.softmax(prdt, dim=-1)\n",
        "\n",
        "        # attention = torch.einsum(\"bhqk,bhkd->bhqd\", prdt, v)\n",
        "        attention = torch.matmul(prdt, v)\n",
        "\n",
        "        concat = attention.transpose(1,2).contiguous().view(batch_size, seq_len_query, self.head_dim*self.n_heads)\n",
        "\n",
        "        out = self.out(concat)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:00:57.060078Z",
          "iopub.status.busy": "2023-10-11T19:00:57.059336Z",
          "iopub.status.idle": "2023-10-11T19:00:57.068189Z",
          "shell.execute_reply": "2023-10-11T19:00:57.067430Z"
        },
        "papermill": {
          "duration": 0.021432,
          "end_time": "2023-10-11T19:00:57.069801",
          "exception": false,
          "start_time": "2023-10-11T19:00:57.048369",
          "status": "completed"
        },
        "tags": [],
        "id": "0sikY6viIVe7"
      },
      "execution_count": null,
      "outputs": [],
      "id": "0sikY6viIVe7"
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim=512, n_heads=8, expansion_factor=4):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.expansion_factor = expansion_factor\n",
        "\n",
        "        self.multiheadattention = MultiHeadAttention(self.embed_dim, self.n_heads)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(self.embed_dim)\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(self.embed_dim, self.embed_dim*self.expansion_factor),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.embed_dim*self.expansion_factor, self.embed_dim)\n",
        "            )\n",
        "        self.norm2 = nn.LayerNorm(self.embed_dim)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "\n",
        "\n",
        "    def forward(self, key, query, value, mask=None):\n",
        "        attention_out = self.multiheadattention(key, query, value, mask)\n",
        "        attention_residual_out = attention_out + query\n",
        "        norm1_out = self.dropout1(self.norm1(attention_residual_out))\n",
        "\n",
        "        feed_forward_out = self.feed_forward(norm1_out)\n",
        "        feed_forward_residual_out = feed_forward_out + norm1_out\n",
        "        norm2_out = self.dropout2(self.norm2(feed_forward_residual_out))\n",
        "\n",
        "        return norm2_out\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, max_seq_len, vocab_size, embed_size=512, num_layers=6, n_heads=8, expansion_factor=4):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "\n",
        "        self.embedding_layer = Embeddings(vocab_size, embed_size)\n",
        "        self.positional_embeddings = PositionalEmbedding(max_seq_len, embed_size)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerBlock(embed_size, n_heads, expansion_factor) for i in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        embed = self.embedding_layer(x)\n",
        "        out = self.positional_embeddings(embed)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, out, out, mask)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:00:57.091804Z",
          "iopub.status.busy": "2023-10-11T19:00:57.091279Z",
          "iopub.status.idle": "2023-10-11T19:00:57.099986Z",
          "shell.execute_reply": "2023-10-11T19:00:57.099221Z"
        },
        "papermill": {
          "duration": 0.021628,
          "end_time": "2023-10-11T19:00:57.101623",
          "exception": false,
          "start_time": "2023-10-11T19:00:57.079995",
          "status": "completed"
        },
        "tags": [],
        "id": "ZpQ8E5iXIVe8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ZpQ8E5iXIVe8"
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, embed_dim=512, n_heads=8, expansion_factor=4):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.expansion_factor = expansion_factor\n",
        "\n",
        "        self.transformer_block = TransformerBlock(embed_dim, n_heads, expansion_factor)\n",
        "        self.attention = MultiHeadAttention(embed_dim, n_heads)\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, key, value, x, tgt_mask, src_mask=None):\n",
        "        attention = self.attention(x, x, x, tgt_mask)\n",
        "        query = self.dropout(self.norm(attention + x))\n",
        "        out = self.transformer_block(key, query, value, src_mask)\n",
        "        return out"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:00:57.123471Z",
          "iopub.status.busy": "2023-10-11T19:00:57.122794Z",
          "iopub.status.idle": "2023-10-11T19:00:57.129017Z",
          "shell.execute_reply": "2023-10-11T19:00:57.128270Z"
        },
        "papermill": {
          "duration": 0.018803,
          "end_time": "2023-10-11T19:00:57.130620",
          "exception": false,
          "start_time": "2023-10-11T19:00:57.111817",
          "status": "completed"
        },
        "tags": [],
        "id": "bPsbGIizIVe8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "bPsbGIizIVe8"
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, max_seq_len, target_vocab_size, embed_dim=512, num_layers=6, expansion_factor=4, n_heads=8):\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "\n",
        "        self.word_embedding = Embeddings(target_vocab_size, embed_dim)\n",
        "        self.position_embedding = PositionalEmbedding(max_seq_len, embed_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [\n",
        "                DecoderBlock(embed_dim, expansion_factor=expansion_factor, n_heads=n_heads)\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embed_dim, target_vocab_size)\n",
        "\n",
        "    def forward(self, x, enc_out, tgt_mask, src_mask=None):\n",
        "        embed = self.word_embedding(x)\n",
        "        x = self.position_embedding(embed)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(enc_out, enc_out, x, tgt_mask, src_mask)\n",
        "\n",
        "        logits = self.fc_out(x)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:00:57.152457Z",
          "iopub.status.busy": "2023-10-11T19:00:57.151793Z",
          "iopub.status.idle": "2023-10-11T19:00:57.158250Z",
          "shell.execute_reply": "2023-10-11T19:00:57.157500Z"
        },
        "papermill": {
          "duration": 0.019072,
          "end_time": "2023-10-11T19:00:57.159870",
          "exception": false,
          "start_time": "2023-10-11T19:00:57.140798",
          "status": "completed"
        },
        "tags": [],
        "id": "h0o0uRqpIVe8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "h0o0uRqpIVe8"
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, embed_dim, src_vocab_size, target_vocab_size, max_seq_length, num_layers=6, expansion_factor=4, n_heads=8, device='cpu'):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.src_pad_idx = -1\n",
        "        self.tgt_pad_idx = -1\n",
        "        self.device = device\n",
        "\n",
        "        self.encoder = TransformerEncoder(max_seq_length,\n",
        "                                          src_vocab_size,\n",
        "                                          embed_dim,\n",
        "                                          num_layers=num_layers,\n",
        "                                          expansion_factor=expansion_factor,\n",
        "                                          n_heads=n_heads)\n",
        "\n",
        "        self.decoder = TransformerDecoder(max_seq_length,\n",
        "                                          target_vocab_size,\n",
        "                                          embed_dim,\n",
        "                                          num_layers=num_layers,\n",
        "                                          expansion_factor=expansion_factor,\n",
        "                                          n_heads=n_heads)\n",
        "\n",
        "\n",
        "    def make_tgt_mask(self, tgt):\n",
        "        batch_size, tgt_len = tgt.shape\n",
        "        tgt_mask = torch.tril(torch.ones((tgt_len, tgt_len))).expand(\n",
        "            batch_size, 1, tgt_len, tgt_len\n",
        "        ).bool()\n",
        "        tgt_pad_mask = (tgt.cpu() != self.tgt_pad_idx).unsqueeze(1).unsqueeze(2).bool()\n",
        "        tgt_mask = tgt_mask & tgt_pad_mask\n",
        "        return tgt_mask.to(self.device)\n",
        "\n",
        "    def make_pad_mask(self, inp, pad_idx):\n",
        "        mask = (inp != pad_idx).unsqueeze(1).unsqueeze(2).bool()\n",
        "        return mask.to(self.device)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        tgt_mask = self.make_tgt_mask(tgt)\n",
        "        src_mask = self.make_pad_mask(src, self.src_pad_idx)\n",
        "        enc_out = self.encoder(src)\n",
        "        outputs = self.decoder(tgt, enc_out, tgt_mask, src_mask)\n",
        "        return outputs"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:00:57.181835Z",
          "iopub.status.busy": "2023-10-11T19:00:57.181094Z",
          "iopub.status.idle": "2023-10-11T19:00:57.188752Z",
          "shell.execute_reply": "2023-10-11T19:00:57.187997Z"
        },
        "papermill": {
          "duration": 0.020216,
          "end_time": "2023-10-11T19:00:57.190327",
          "exception": false,
          "start_time": "2023-10-11T19:00:57.170111",
          "status": "completed"
        },
        "tags": [],
        "id": "caqr4wz9IVe8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "caqr4wz9IVe8"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext\n"
      ],
      "metadata": {
        "id": "Acg6KG7lI1Yu",
        "outputId": "562d31ce-1f4e-4dd9-c157-98eff4112089",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Acg6KG7lI1Yu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext\n",
            "  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare for Training"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.009895,
          "end_time": "2023-10-11T19:00:57.210795",
          "exception": false,
          "start_time": "2023-10-11T19:00:57.200900",
          "status": "completed"
        },
        "tags": [],
        "id": "PCKuL10HIVe8"
      },
      "id": "PCKuL10HIVe8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Dataset"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.010004,
          "end_time": "2023-10-11T19:00:57.231502",
          "exception": false,
          "start_time": "2023-10-11T19:00:57.221498",
          "status": "completed"
        },
        "tags": [],
        "id": "9reyC_yJIVe9"
      },
      "id": "9reyC_yJIVe9"
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import spacy\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchtext.vocab import vocab\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from datasets import load_dataset\n",
        "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
        "spacy_ger = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:00:57.252987Z",
          "iopub.status.busy": "2023-10-11T19:00:57.252741Z",
          "iopub.status.idle": "2023-10-11T19:01:07.139092Z",
          "shell.execute_reply": "2023-10-11T19:01:07.138136Z"
        },
        "papermill": {
          "duration": 9.89973,
          "end_time": "2023-10-11T19:01:07.141265",
          "exception": false,
          "start_time": "2023-10-11T19:00:57.241535",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "GfeQBwZoIVe9",
        "outputId": "6b029b9a-ea43-411e-fc4a-6c064e0cfc5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchtext'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-63063c1eb614>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "id": "GfeQBwZoIVe9"
    },
    {
      "cell_type": "code",
      "source": [
        "multi30k = load_dataset(\"bentrevett/multi30k\")\n",
        "multi30k"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:07.164434Z",
          "iopub.status.busy": "2023-10-11T19:01:07.163866Z",
          "iopub.status.idle": "2023-10-11T19:01:10.011244Z",
          "shell.execute_reply": "2023-10-11T19:01:10.010433Z"
        },
        "papermill": {
          "duration": 2.861388,
          "end_time": "2023-10-11T19:01:10.013759",
          "exception": false,
          "start_time": "2023-10-11T19:01:07.152371",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "7b898e5367734856b4b68887dbad4f79",
            "b5df63e672e94915b5d7c2484b014f32",
            "4862d9fb6c5e40a2a07b381a1c007943",
            "599894ef11ac43e0987bfdad8a3fde6f",
            "b2f07f2d13f14c0188cbfdb292ca2d60"
          ]
        },
        "id": "31BUwsVLIVe9",
        "outputId": "1bab2b40-fadd-4066-ef5f-c8a446d45b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Downloading and preparing dataset json/bentrevett--multi30k to /root/.cache/huggingface/datasets/json/bentrevett--multi30k-110b735679f9d585/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b898e5367734856b4b68887dbad4f79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5df63e672e94915b5d7c2484b014f32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/4.60M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4862d9fb6c5e40a2a07b381a1c007943",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/156k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "599894ef11ac43e0987bfdad8a3fde6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/bentrevett--multi30k-110b735679f9d585/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2f07f2d13f14c0188cbfdb292ca2d60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['en', 'de'],\n",
              "        num_rows: 29000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['en', 'de'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {}
        }
      ],
      "id": "31BUwsVLIVe9"
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = multi30k['train'], multi30k['test']"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:10.056959Z",
          "iopub.status.busy": "2023-10-11T19:01:10.056562Z",
          "iopub.status.idle": "2023-10-11T19:01:10.060938Z",
          "shell.execute_reply": "2023-10-11T19:01:10.060155Z"
        },
        "papermill": {
          "duration": 0.029602,
          "end_time": "2023-10-11T19:01:10.064510",
          "exception": false,
          "start_time": "2023-10-11T19:01:10.034908",
          "status": "completed"
        },
        "tags": [],
        "id": "nB4klgw6IVe9"
      },
      "execution_count": null,
      "outputs": [],
      "id": "nB4klgw6IVe9"
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer_ger(text):\n",
        "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "def tokenizer_eng(text):\n",
        "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:10.104678Z",
          "iopub.status.busy": "2023-10-11T19:01:10.104378Z",
          "iopub.status.idle": "2023-10-11T19:01:10.108862Z",
          "shell.execute_reply": "2023-10-11T19:01:10.108140Z"
        },
        "papermill": {
          "duration": 0.028249,
          "end_time": "2023-10-11T19:01:10.112192",
          "exception": false,
          "start_time": "2023-10-11T19:01:10.083943",
          "status": "completed"
        },
        "tags": [],
        "id": "JAsxs7E6IVe9"
      },
      "execution_count": null,
      "outputs": [],
      "id": "JAsxs7E6IVe9"
    },
    {
      "cell_type": "code",
      "source": [
        "ger_counter = Counter()\n",
        "eng_counter = Counter()\n",
        "for data in tqdm(train):\n",
        "    ger_counter.update(tokenizer_ger(data['de'].lower()))\n",
        "    eng_counter.update(tokenizer_eng(data['en'].lower()))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:10.151286Z",
          "iopub.status.busy": "2023-10-11T19:01:10.150842Z",
          "iopub.status.idle": "2023-10-11T19:01:16.751627Z",
          "shell.execute_reply": "2023-10-11T19:01:16.750272Z"
        },
        "papermill": {
          "duration": 6.622363,
          "end_time": "2023-10-11T19:01:16.753393",
          "exception": false,
          "start_time": "2023-10-11T19:01:10.131030",
          "status": "completed"
        },
        "tags": [],
        "id": "T-JJIg0KIVe9",
        "outputId": "1364b011-0496-42de-8c6c-ab05d7212bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 29000/29000 [00:06<00:00, 4400.23it/s]\n"
        }
      ],
      "id": "T-JJIg0KIVe9"
    },
    {
      "cell_type": "code",
      "source": [
        "ger_vocab = vocab(ger_counter, min_freq=2, specials=(\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"))\n",
        "eng_vocab = vocab(eng_counter, min_freq=2, specials=(\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"))\n",
        "ger_vocab.set_default_index(ger_vocab[\"<unk>\"])\n",
        "eng_vocab.set_default_index(eng_vocab[\"<unk>\"])\n",
        "print(f\"Size of German Vocab : {len(ger_vocab)}\\n Size of English Vocab : {len(eng_vocab)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:16.782737Z",
          "iopub.status.busy": "2023-10-11T19:01:16.782223Z",
          "iopub.status.idle": "2023-10-11T19:01:16.974356Z",
          "shell.execute_reply": "2023-10-11T19:01:16.973237Z"
        },
        "papermill": {
          "duration": 0.208818,
          "end_time": "2023-10-11T19:01:16.976309",
          "exception": false,
          "start_time": "2023-10-11T19:01:16.767491",
          "status": "completed"
        },
        "tags": [],
        "id": "hERAkMlPIVe9",
        "outputId": "5884f4ce-9329-4e60-8179-54a6a047117d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Size of German Vocab : 7853\n\n Size of English Vocab : 5893\n"
        }
      ],
      "id": "hERAkMlPIVe9"
    },
    {
      "cell_type": "code",
      "source": [
        "text_transform_eng = lambda x: [eng_vocab['<sos>']] + [eng_vocab[token.lower()] for token in tokenizer_eng(x)] + [eng_vocab['<eos>']]\n",
        "text_transform_ger = lambda x: [ger_vocab['<sos>']] + [ger_vocab[token.lower()] for token in tokenizer_ger(x)] + [ger_vocab['<eos>']]"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:17.005301Z",
          "iopub.status.busy": "2023-10-11T19:01:17.005033Z",
          "iopub.status.idle": "2023-10-11T19:01:17.009936Z",
          "shell.execute_reply": "2023-10-11T19:01:17.008999Z"
        },
        "papermill": {
          "duration": 0.021221,
          "end_time": "2023-10-11T19:01:17.011641",
          "exception": false,
          "start_time": "2023-10-11T19:01:16.990420",
          "status": "completed"
        },
        "tags": [],
        "id": "Uios5LZOIVe9"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Uios5LZOIVe9"
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    src_list, tgt_list = [], []\n",
        "    for data in batch:\n",
        "        src_list.append(torch.tensor(text_transform_ger(data['de'])))\n",
        "        tgt_list.append(torch.tensor(text_transform_eng(data['en'])))\n",
        "\n",
        "    src_list = pad_sequence(src_list, padding_value=ger_vocab['<pad>']).T\n",
        "    tgt_list = pad_sequence(tgt_list, padding_value=eng_vocab['<pad>']).T\n",
        "\n",
        "    inp = {\n",
        "        \"src\": src_list,\n",
        "        \"tgt\": tgt_list\n",
        "    }\n",
        "\n",
        "    return inp\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:17.040281Z",
          "iopub.status.busy": "2023-10-11T19:01:17.039523Z",
          "iopub.status.idle": "2023-10-11T19:01:17.044906Z",
          "shell.execute_reply": "2023-10-11T19:01:17.044105Z"
        },
        "papermill": {
          "duration": 0.021442,
          "end_time": "2023-10-11T19:01:17.046503",
          "exception": false,
          "start_time": "2023-10-11T19:01:17.025061",
          "status": "completed"
        },
        "tags": [],
        "id": "aLzcg2VwIVe-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "aLzcg2VwIVe-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Training Parameters and DataLoader"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.013284,
          "end_time": "2023-10-11T19:01:17.073407",
          "exception": false,
          "start_time": "2023-10-11T19:01:17.060123",
          "status": "completed"
        },
        "tags": [],
        "id": "rtv7joqVIVe-"
      },
      "id": "rtv7joqVIVe-"
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "batch_size = 16\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 0.001\n",
        "writer = SummaryWriter(f\"runs/loss\")\n",
        "\n",
        "train_dataloader = DataLoader(train,\n",
        "                              collate_fn=collate_batch,\n",
        "                              shuffle=True,\n",
        "                              batch_size=batch_size,\n",
        "                              pin_memory=True)\n",
        "test_dataloader = DataLoader(test,\n",
        "                              collate_fn=collate_batch,\n",
        "                              shuffle=False,\n",
        "                              batch_size=batch_size,\n",
        "                              pin_memory=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transformer_model = Transformer(embed_dim=512,\n",
        "                                src_vocab_size=len(ger_vocab),\n",
        "                                target_vocab_size=len(eng_vocab),\n",
        "                                max_seq_length=50,\n",
        "                                num_layers=6,\n",
        "                                expansion_factor=4,\n",
        "                                n_heads=8,\n",
        "                                device=device)\n",
        "transformer_model.src_pad_idx = ger_vocab['<pad>']\n",
        "transformer_model.tgt_pad_idx = eng_vocab['<pad>']"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:17.101752Z",
          "iopub.status.busy": "2023-10-11T19:01:17.101362Z",
          "iopub.status.idle": "2023-10-11T19:01:17.808838Z",
          "shell.execute_reply": "2023-10-11T19:01:17.807910Z"
        },
        "papermill": {
          "duration": 0.72394,
          "end_time": "2023-10-11T19:01:17.810895",
          "exception": false,
          "start_time": "2023-10-11T19:01:17.086955",
          "status": "completed"
        },
        "tags": [],
        "id": "CH7mM6m-IVe-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "CH7mM6m-IVe-"
    },
    {
      "cell_type": "code",
      "source": [
        "total_steps = num_epochs*math.ceil(len(train)/batch_size)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
        "                                               max_lr=learning_rate,\n",
        "                                               total_steps=total_steps,\n",
        "                                               pct_start=0.33,\n",
        "                                               div_factor=1e3,\n",
        "                                               final_div_factor=1e2)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=eng_vocab['<pad>'])\n",
        "\n",
        "# load_model = False\n",
        "# if load_model:\n",
        "#     transformer_model.load_state_dict(torch.load(\"/kaggle/input/nmt-ger-eng-weights/my_checkpoint.pth.tar\")['state_dict'])\n",
        "\n",
        "transformer_model = transformer_model.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:17.840081Z",
          "iopub.status.busy": "2023-10-11T19:01:17.839505Z",
          "iopub.status.idle": "2023-10-11T19:01:17.906705Z",
          "shell.execute_reply": "2023-10-11T19:01:17.905837Z"
        },
        "papermill": {
          "duration": 0.083598,
          "end_time": "2023-10-11T19:01:17.908631",
          "exception": false,
          "start_time": "2023-10-11T19:01:17.825033",
          "status": "completed"
        },
        "tags": [],
        "id": "qwbMMW_HIVe-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "qwbMMW_HIVe-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beam Search Code (Naive Implementation)"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.013246,
          "end_time": "2023-10-11T19:01:17.935592",
          "exception": false,
          "start_time": "2023-10-11T19:01:17.922346",
          "status": "completed"
        },
        "tags": [],
        "id": "nJagIzSjIVe-"
      },
      "id": "nJagIzSjIVe-"
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_seq_beam_search(model, src, device, k=2, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    src_mask = model.make_pad_mask(src, model.src_pad_idx)\n",
        "    with torch.no_grad():\n",
        "        enc_out = model.encoder(src, src_mask)\n",
        "\n",
        "    # beam search\n",
        "\n",
        "    candidates = [(torch.LongTensor([eng_vocab['<sos>']]), 0.0)]\n",
        "\n",
        "    final_translations = []\n",
        "\n",
        "    for a in range(max_len):\n",
        "\n",
        "        input_batch = torch.concat([c[0].unsqueeze(0) for c in candidates], dim=0).to(device)\n",
        "\n",
        "        if a>0:\n",
        "            enc_out_repeat = enc_out.repeat(input_batch.shape[0], 1, 1)\n",
        "        else:\n",
        "            enc_out_repeat = enc_out\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model.decoder(input_batch, enc_out_repeat, model.make_tgt_mask(input_batch), src_mask).detach().cpu()\n",
        "        output[:, :, :2] = float(\"-1e20\")\n",
        "        output = output[:, -1, :]\n",
        "        output = F.log_softmax(output, dim=-1)\n",
        "\n",
        "\n",
        "        topk_output = torch.topk(output, k, dim=-1)\n",
        "        topk_tokens = topk_output.indices\n",
        "        topk_scores = topk_output.values\n",
        "\n",
        "\n",
        "        new_seq = torch.concat([torch.concat([torch.vstack([c[0] for _ in range(k)]), topk_tokens[i].reshape(-1,1)], dim=-1) for i,c in enumerate(candidates)], dim=0)\n",
        "        new_scores = torch.concat([c[1] + topk_scores[i] for i,c in enumerate(candidates)], dim=0)\n",
        "\n",
        "\n",
        "        topk_new = torch.topk(new_scores, k=k).indices.tolist()\n",
        "\n",
        "        new_candidates = []\n",
        "\n",
        "        for i in range(k):\n",
        "            if new_seq[topk_new[i]][-1] == eng_vocab[\"<eos>\"] or a==max_len-1:\n",
        "                final_translations.append((new_seq[topk_new[i]].tolist(), int(new_scores[topk_new[i]])))\n",
        "            else:\n",
        "                new_candidate = (new_seq[topk_new[i]], new_scores[topk_new[i]])\n",
        "                new_candidates.append(new_candidate)\n",
        "\n",
        "\n",
        "        if len(new_candidates) > 0:\n",
        "            candidates = new_candidates\n",
        "        else:\n",
        "            break\n",
        "\n",
        "\n",
        "    return final_translations"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:17.964167Z",
          "iopub.status.busy": "2023-10-11T19:01:17.963890Z",
          "iopub.status.idle": "2023-10-11T19:01:17.974088Z",
          "shell.execute_reply": "2023-10-11T19:01:17.973297Z"
        },
        "papermill": {
          "duration": 0.026614,
          "end_time": "2023-10-11T19:01:17.975818",
          "exception": false,
          "start_time": "2023-10-11T19:01:17.949204",
          "status": "completed"
        },
        "tags": [],
        "id": "8fox1GcTIVe-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "8fox1GcTIVe-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Greedy Sequence Generation"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.013501,
          "end_time": "2023-10-11T19:01:18.002866",
          "exception": false,
          "start_time": "2023-10-11T19:01:17.989365",
          "status": "completed"
        },
        "tags": [],
        "id": "praMPSkgIVe-"
      },
      "id": "praMPSkgIVe-"
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_seq(model, src, device, max_len=50):\n",
        "    model.eval()\n",
        "    src_mask = model.make_pad_mask(src, model.src_pad_idx)\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src, src_mask)\n",
        "    tgt_indexes = [eng_vocab[\"<sos>\"]]\n",
        "    for i in range(max_len):\n",
        "        tgt_tensor = torch.LongTensor(tgt_indexes).unsqueeze(0).to(device)\n",
        "        tgt_mask = model.make_tgt_mask(tgt_tensor)\n",
        "        with torch.no_grad():\n",
        "            output = model.decoder(tgt_tensor, enc_src, tgt_mask, src_mask)\n",
        "        output[:, :, :2] = float(\"-1e20\")  # cannot predict <unk>, <pad> token\n",
        "        output = output[:, -1, :] # pick the last token\n",
        "        output = F.softmax(output, dim=-1)\n",
        "        pred_token = output.argmax(-1).item()\n",
        "        tgt_indexes.append(pred_token)\n",
        "        if pred_token == eng_vocab[\"<eos>\"]:\n",
        "            break\n",
        "    return tgt_indexes"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:18.031985Z",
          "iopub.status.busy": "2023-10-11T19:01:18.031220Z",
          "iopub.status.idle": "2023-10-11T19:01:18.038128Z",
          "shell.execute_reply": "2023-10-11T19:01:18.037344Z"
        },
        "papermill": {
          "duration": 0.023107,
          "end_time": "2023-10-11T19:01:18.039743",
          "exception": false,
          "start_time": "2023-10-11T19:01:18.016636",
          "status": "completed"
        },
        "tags": [],
        "id": "CqhG_bpeIVe-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "CqhG_bpeIVe-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Functions"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.013819,
          "end_time": "2023-10-11T19:01:18.066991",
          "exception": false,
          "start_time": "2023-10-11T19:01:18.053172",
          "status": "completed"
        },
        "tags": [],
        "id": "RH0wQsyyIVe-"
      },
      "id": "RH0wQsyyIVe-"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "class AvgMeter:\n",
        "    def __init__(self, name=\"Metric\"):\n",
        "        self.name = name\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.avg, self.sum, self.count = [0]*3\n",
        "\n",
        "    def update(self, val, count=1):\n",
        "        self.count += count\n",
        "        self.sum += val * count\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __repr__(self):\n",
        "        text = f\"{self.name}: {self.avg:.4f}\"\n",
        "        return text"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:18.095691Z",
          "iopub.status.busy": "2023-10-11T19:01:18.094848Z",
          "iopub.status.idle": "2023-10-11T19:01:18.101027Z",
          "shell.execute_reply": "2023-10-11T19:01:18.100235Z"
        },
        "papermill": {
          "duration": 0.02218,
          "end_time": "2023-10-11T19:01:18.102715",
          "exception": false,
          "start_time": "2023-10-11T19:01:18.080535",
          "status": "completed"
        },
        "tags": [],
        "id": "FfficA0LIVe-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "FfficA0LIVe-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Training"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.013465,
          "end_time": "2023-10-11T19:01:18.129748",
          "exception": false,
          "start_time": "2023-10-11T19:01:18.116283",
          "status": "completed"
        },
        "tags": [],
        "id": "qM-UFPUOIVe-"
      },
      "id": "qM-UFPUOIVe-"
    },
    {
      "cell_type": "code",
      "source": [
        "step = 0\n",
        "for epoch in range(1, num_epochs+1):\n",
        "\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "\n",
        "    checkpoint = {\"state_dict\": transformer_model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
        "    torch.save(checkpoint, \"my_checkpoint.pth.tar\")\n",
        "\n",
        "    loss_meter = AvgMeter()\n",
        "    transformer_model.train()\n",
        "\n",
        "    bar = tqdm(train_dataloader, total=math.ceil(len(train)/batch_size))\n",
        "\n",
        "    for idx, data in enumerate(bar):\n",
        "\n",
        "        german = data[\"src\"].to(device)\n",
        "        english = data[\"tgt\"].to(device)\n",
        "\n",
        "        count = german.shape[0]\n",
        "\n",
        "        output = transformer_model(german, english[:,:-1])\n",
        "\n",
        "        output = output.reshape(-1, output.shape[2])\n",
        "        english = english[:, 1:]\n",
        "        english = english.reshape(-1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(output, english)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(transformer_model.parameters(), max_norm=1)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "        step += 1\n",
        "\n",
        "        loss_meter.update(loss.item(), count)\n",
        "        bar.set_postfix(loss=loss_meter.avg, lr=get_lr(optimizer), step=step)\n",
        "\n",
        "    # Example Generation (Greedy Decode)\n",
        "    ex = test[random.randint(0, len(test))]\n",
        "    sentence = ex['de']\n",
        "    src_indexes = torch.tensor(text_transform_ger(sentence)).unsqueeze(0).to(device)\n",
        "    translated_sentence_idx = translate_seq(transformer_model, src_indexes, device=device, max_len=30)\n",
        "    translated_sentence = [eng_vocab.get_itos()[i] for i in translated_sentence_idx]\n",
        "    print(f\"\\nExample sentence: \\n {sentence}\\n\")\n",
        "    print(f\"Original Translation : \\n {' '.join(translated_sentence[1:-1])}\\n\")\n",
        "    print(f\"Generated Translation : \\n{ex['en']}\\n\")\n",
        "\n",
        "    del src_indexes, ex, sentence, translated_sentence_idx, translated_sentence, checkpoint\n",
        "    torch.cuda.empty_cache()\n",
        "    _ = gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:01:18.158523Z",
          "iopub.status.busy": "2023-10-11T19:01:18.157806Z",
          "iopub.status.idle": "2023-10-11T19:46:23.222371Z",
          "shell.execute_reply": "2023-10-11T19:46:23.220694Z"
        },
        "papermill": {
          "duration": 2705.081154,
          "end_time": "2023-10-11T19:46:23.224271",
          "exception": false,
          "start_time": "2023-10-11T19:01:18.143117",
          "status": "completed"
        },
        "tags": [],
        "id": "9xSNhl_JIVe_",
        "outputId": "c90b39e6-c300-4903-c5d3-8bb47e996834"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[Epoch 1 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:28<00:00, 20.45it/s, loss=6.01, lr=2.59e-5, step=1813]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Zwei junge Männer fahren auf einem sehr kleinen Wagen voller Kartoffeln, der von einem Pferd gezogen wird.\n\n\n\nOriginal Translation : \n\n a man in a group of a group of people in the street in the street .\n\n\n\nGenerated Translation : \n\nTwo young men riding on a very small horse-drawn wagon full of potatoes.\n\n\n\n[Epoch 2 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:25<00:00, 21.12it/s, loss=4.04, lr=9.83e-5, step=3626]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Zwei indische Männer nehmen an einer Zeremonie teil.\n\n\n\nOriginal Translation : \n\n two men are playing a small men are playing a large sidewalk .\n\n\n\nGenerated Translation : \n\nTwo Indian men participating in a ceremony.\n\n\n\n[Epoch 3 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:26<00:00, 20.98it/s, loss=3.38, lr=0.000211, step=5439]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Eine Frau in einem pinken Pulli und einer Schürze putzt einen Tisch mit einem Schwamm.\n\n\n\nOriginal Translation : \n\n a woman and a woman in a pink dress and a woman in a table with a table .\n\n\n\nGenerated Translation : \n\nA woman in a pink sweater and an apron, cleaning a table with a sponge.\n\n\n\n[Epoch 4 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:26<00:00, 20.97it/s, loss=2.87, lr=0.000352, step=7252]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein lächelnder Mann mit Rucksack streckt vor einem Jungen mit Brille die Fäuste in die Luft.\n\n\n\nOriginal Translation : \n\n a man with glasses is wearing a backpack in the air with a camera in the air .\n\n\n\nGenerated Translation : \n\nA smiling man wearing a backpack holds his fists up in front of a boy in glasses.\n\n\n\n[Epoch 5 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:26<00:00, 20.94it/s, loss=2.54, lr=0.000508, step=9065]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Hund springt um einen Ball zu fangen, während ein anderer zusieht.\n\n\n\nOriginal Translation : \n\n a dog jumps to catch a ball while another dog watches .\n\n\n\nGenerated Translation : \n\nOne dog leaps to catch a softball while another looks on.\n\n\n\n[Epoch 6 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:26<00:00, 21.00it/s, loss=2.33, lr=0.000664, step=10878]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Junge posiert mit einem großen grünen Insekt auf der Nase.\n\n\n\nOriginal Translation : \n\n a boy is posing on a large green mat with a large guitar .\n\n\n\nGenerated Translation : \n\nA boy poses with a large green insect on his nose.\n\n\n\n[Epoch 7 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:26<00:00, 20.85it/s, loss=2.2, lr=0.000803, step=12691]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Viele Menschen sitzen um ein Zelt im Freien.\n\n\n\nOriginal Translation : \n\n a tent is sitting around many people outside at a tent .\n\n\n\nGenerated Translation : \n\nMany people are sitting around a tent outside.\n\n\n\n[Epoch 8 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:26<00:00, 20.91it/s, loss=2.08, lr=0.000912, step=14504]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Eine Familie spaziert durch einen Park.\n\n\n\nOriginal Translation : \n\n a family walks through a park .\n\n\n\nGenerated Translation : \n\nA Family going for a walk in a park.\n\n\n\n[Epoch 9 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:27<00:00, 20.76it/s, loss=1.98, lr=0.00098, step=16317]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Diese Personen klettern die Stufen zum Berg hoch\n\n\n\nOriginal Translation : \n\n these people climb up stairs to the hill .\n\n\n\nGenerated Translation : \n\nThese people are climbing the steps to go the mountain\n\n\n\n[Epoch 10 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:27<00:00, 20.67it/s, loss=1.9, lr=0.001, step=18130]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Eine Gruppe klettert bei kaltem Wetter.\n\n\n\nOriginal Translation : \n\n a group of people are climbing a fire at dusk .\n\n\n\nGenerated Translation : \n\nA group of people are climbing in cold weather.\n\n\n\n[Epoch 11 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:27<00:00, 20.64it/s, loss=1.81, lr=0.000993, step=19943]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Das ist eine große Menschengruppe, die im Freien auf Bänken sitzt.\n\n\n\nOriginal Translation : \n\n a large group of people sitting outside on stone bench .\n\n\n\nGenerated Translation : \n\nThis is a large group of people sitting outside on benches.\n\n\n\n[Epoch 12 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:28<00:00, 20.54it/s, loss=1.73, lr=0.000973, step=21756]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Junge steht mit drei Mädchen.\n\n\n\nOriginal Translation : \n\n a boy is standing with three girls .\n\n\n\nGenerated Translation : \n\nA boy stands with three girls.\n\n\n\n[Epoch 13 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:27<00:00, 20.66it/s, loss=1.65, lr=0.000942, step=23569]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Hockeyspiel wird vor großem Publikum gespielt.\n\n\n\nOriginal Translation : \n\n a hockey player smiles for an audience .\n\n\n\nGenerated Translation : \n\nA hockey game is being played with lots of people watching it.\n\n\n\n[Epoch 14 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:28<00:00, 20.49it/s, loss=1.57, lr=0.000901, step=25382]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Zwei Männer verkaufen Obst auf einem Obstmarkt.\n\n\n\nOriginal Translation : \n\n two men selling meat on a street .\n\n\n\nGenerated Translation : \n\nTwo men selling fruit at a fruit market.\n\n\n\n[Epoch 15 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:28<00:00, 20.46it/s, loss=1.47, lr=0.000849, step=27195]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein kleines Kind in einem blau-weißen T-Shirt hält glücklich einen gelben Plastik-Alligator.\n\n\n\nOriginal Translation : \n\n a young child in a blue and yellow shirt holding a yellow balloon .\n\n\n\nGenerated Translation : \n\nA small child wearing a blue and white t-shirt happily holding a yellow plastic alligator.\n\n\n\n[Epoch 16 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:28<00:00, 20.54it/s, loss=1.38, lr=0.000789, step=29008]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Eine Frau sitzt neben ihrer Tasche und sieht Hunden im Park zu.\n\n\n\nOriginal Translation : \n\n a woman is sitting in the park looking at her dog while sitting next to her .\n\n\n\nGenerated Translation : \n\nA woman sitting next to her purse watching dogs at the park.\n\n\n\n[Epoch 17 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:27<00:00, 20.61it/s, loss=1.28, lr=0.000722, step=30821]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Junge in einem roten Badeanzug spielt im Wasser.\n\n\n\nOriginal Translation : \n\n a boy in a red bathing suit playing in the water .\n\n\n\nGenerated Translation : \n\nA boy in a red suit plays in the water.\n\n\n\n[Epoch 18 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:29<00:00, 20.37it/s, loss=1.19, lr=0.00065, step=32634]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Kind planscht im Wasser.\n\n\n\nOriginal Translation : \n\n a child splashes in the water .\n\n\n\nGenerated Translation : \n\nA child is splashing in the water\n\n\n\n[Epoch 19 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:29<00:00, 20.31it/s, loss=1.1, lr=0.000574, step=34447]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Sechs Leute fahren Mountainbikes durch eine Dschungellandschaft.\n\n\n\nOriginal Translation : \n\n six people are riding through a motocross course .\n\n\n\nGenerated Translation : \n\nSix people ride mountain bikes through a jungle environment.\n\n\n\n[Epoch 20 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:28<00:00, 20.49it/s, loss=1.02, lr=0.000496, step=36260]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Kind in einem weißen Karateanzug übt eine Bewegung.\n\n\n\nOriginal Translation : \n\n a child in a white uniform is practicing a martial arts move .\n\n\n\nGenerated Translation : \n\nA child in a white karate outfit practicing a move\n\n\n\n[Epoch 21 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:29<00:00, 20.21it/s, loss=0.926, lr=0.000418, step=38073]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Mann in einem gelben Mantel achtet auf ein Feuer, ein Junge im Anorak sieht zu.\n\n\n\nOriginal Translation : \n\n a man in a yellow coat looks at a fire in a fire scene .\n\n\n\nGenerated Translation : \n\nA man in a yellow coat tends a fire, a boy in a parka watches.\n\n\n\n[Epoch 22 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:29<00:00, 20.18it/s, loss=0.845, lr=0.000342, step=39886]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Zwei Hunde beschnuppern sich gegenseitig Nase an Nase.\n\n\n\nOriginal Translation : \n\n two dogs are wrestling on their nose that are empty .\n\n\n\nGenerated Translation : \n\nTwo dogs are nuzzling each other nose to nose.\n\n\n\n[Epoch 23 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:28<00:00, 20.44it/s, loss=0.766, lr=0.000271, step=41699]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Mann steht am Rand einer Mauer und fällt gleich runter.\n\n\n\nOriginal Translation : \n\n a man stands at the side of a wall about to land .\n\n\n\nGenerated Translation : \n\nA man on the edge of a wall about to fall off.\n\n\n\n[Epoch 24 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:30<00:00, 20.09it/s, loss=0.696, lr=0.000204, step=43512]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Kind sitzt auf den Schultern einer Frau und klatscht.\n\n\n\nOriginal Translation : \n\n a child and child are sitting on a carousel laughing .\n\n\n\nGenerated Translation : \n\nA child claps while riding on a woman's shoulders.\n\n\n\n[Epoch 25 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:29<00:00, 20.33it/s, loss=0.637, lr=0.000145, step=45325]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Eine Gruppe Asiatischer Jungen wartet am Grill darauf, dass Fleisch gar wird.\n\n\n\nOriginal Translation : \n\n a group of asian boys wait for money at the grill .\n\n\n\nGenerated Translation : \n\nGroup of Asian boys wait for meat to cook over barbecue.\n\n\n\n[Epoch 26 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:28<00:00, 20.49it/s, loss=0.588, lr=9.46e-5, step=47138]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Eine Frau sitzt gegen eine Ziegelwand gelehnt in einem Gebäude.\n\n\n\nOriginal Translation : \n\n a woman sits against a brick wall in a building .\n\n\n\nGenerated Translation : \n\nA woman sitting against a brick wall inside a building.\n\n\n\n[Epoch 27 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:31<00:00, 19.86it/s, loss=0.55, lr=5.4e-5, step=48951]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Eine junge blonde Frau hält ein weißes Seil an einem sonnigen Tag.\n\n\n\nOriginal Translation : \n\n a young blond woman holds a white rope on a sunny day .\n\n\n\nGenerated Translation : \n\nA young blond woman holds a white rope on a sunny day.\n\n\n\n[Epoch 28 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:29<00:00, 20.33it/s, loss=0.523, lr=2.42e-5, step=50764]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Hund dreht sich auf dem Gras um einem fliegenden Ball nachzulaufen.\n\n\n\nOriginal Translation : \n\n a dog turns around on the grass with a ball around a dog .\n\n\n\nGenerated Translation : \n\nA dog turns on the grass to persue a flying ball.\n\n\n\n[Epoch 29 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:30<00:00, 20.12it/s, loss=0.507, lr=6.1e-6, step=52577]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Eine Frau in einem schwarzen Tank-Top mit einem Kreuz-Halsband blickt kurz vor Sonnenuntergang in die Ferne.\n\n\n\nOriginal Translation : \n\n a woman in a black tank top looks on as she begins to go in the distance in front of a sunset .\n\n\n\nGenerated Translation : \n\nA woman wearing a black tank top and a cross necklace stares off into the distance near sunset.\n\n\n\n[Epoch 30 / 30]\n"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1813/1813 [01:28<00:00, 20.37it/s, loss=0.5, lr=1e-8, step=54390]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\nExample sentence: \n\n Ein Afroamerikaner geht die Straße hinunter.\n\n\n\nOriginal Translation : \n\n an african american man walking down the street .\n\n\n\nGenerated Translation : \n\nAn African American man walking down the street.\n\n\n"
        }
      ],
      "id": "9xSNhl_JIVe_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Beam Search Generation from Test Data"
      ],
      "metadata": {
        "papermill": {
          "duration": 3.538235,
          "end_time": "2023-10-11T19:46:30.118313",
          "exception": false,
          "start_time": "2023-10-11T19:46:26.580078",
          "status": "completed"
        },
        "tags": [],
        "id": "pDfEjcTXIVe_"
      },
      "id": "pDfEjcTXIVe_"
    },
    {
      "cell_type": "code",
      "source": [
        "for n in range(5):\n",
        "    print(f\"Example {n+1}\\n\")\n",
        "    ex = test[random.randint(0, len(test))]\n",
        "    sentence = ex['de']\n",
        "    src_indexes = torch.tensor(text_transform_ger(sentence)).unsqueeze(0).to(device)\n",
        "    k = 3\n",
        "    translated_sentence_ids = translate_seq_beam_search(transformer_model, src_indexes, k=k, device=device, max_len=30)\n",
        "    translated_sentence_ids = sorted(translated_sentence_ids, key= lambda x: x[1], reverse=True)\n",
        "    translations = [[eng_vocab.get_itos()[i] for i in translated_sentence[0]] for translated_sentence in translated_sentence_ids]\n",
        "    print(f\"German : {ex['de']}\")\n",
        "    print(f\"English : {ex['en']}\\n\")\n",
        "    print(f\"English Translations generated:\\n\")\n",
        "    for i in range(k):\n",
        "        for w in translations[i]:\n",
        "            if w in ['<sos>', '<eos>', '<pad>', '<unk>']:\n",
        "                continue\n",
        "            print(w, end=\" \")\n",
        "        print()\n",
        "    print(\"---------------------------------------------------------------------\\n\")\n",
        "\n",
        "del src_indexes, ex, sentence, translated_sentence_ids, translations\n",
        "torch.cuda.empty_cache()\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:46:36.905491Z",
          "iopub.status.busy": "2023-10-11T19:46:36.905137Z",
          "iopub.status.idle": "2023-10-11T19:46:38.556855Z",
          "shell.execute_reply": "2023-10-11T19:46:38.555794Z"
        },
        "papermill": {
          "duration": 5.048569,
          "end_time": "2023-10-11T19:46:38.559046",
          "exception": false,
          "start_time": "2023-10-11T19:46:33.510477",
          "status": "completed"
        },
        "tags": [],
        "id": "Zk_eX0_DIVe_",
        "outputId": "6f714a98-cfc2-4194-ff3f-35c93319bb62"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Example 1\n\n\n\nGerman : Zwei Männer verkaufen Obst auf einem Obstmarkt.\n\nEnglish : Two men selling fruit at a fruit market.\n\n\n\nEnglish Translations generated:\n\n\n\ntwo men are selling fruit on a fruit stand . \n\ntwo men selling fruit on a mobile market . \n\ntwo men sell fruit on a mobile market . \n\n---------------------------------------------------------------------\n\n\n\nExample 2\n\n\n\nGerman : Ein junges Mädchen steht neben einer gelben Katze auf einer Küchenarbeitsplatte.\n\nEnglish : A young girl standing next to a yellow cat on a kitchen countertop.\n\n\n\nEnglish Translations generated:\n\n\n\na young girl stands on a yellow car next to a cat . \n\na young girl is standing on a yellow car next to a cat . \n\na young girl stands on a yellow and yellow cat next to a cat . \n\n---------------------------------------------------------------------\n\n\n\nExample 3\n\n\n\nGerman : Eine Frau auf einem Boot namens \"El Corazon\" lässt schwarze Gewichte ins Wasser fallen.\n\nEnglish : A woman on a boat named \"El Corazon\" drops black weights into the water.\n\n\n\nEnglish Translations generated:\n\n\n\na black boat is being put out into the water by a woman 's boat . \n\na black boat is being pulled out into the water by a woman 's boat . \n\na black boat is being put out into the water by a black boat that is filled with water . \n\n---------------------------------------------------------------------\n\n\n\nExample 4\n\n\n\nGerman : Eine Frau bläst eine Pusteblume auf einer Wiese.\n\nEnglish : A woman in a grassy field blows on a dandelion.\n\n\n\nEnglish Translations generated:\n\n\n\na woman is blowing bubbles on a grassy field . \n\na woman is blowing bubbles on a grassy lawn . \n\na woman is blowing bubbles in a grassy field . \n\n---------------------------------------------------------------------\n\n\n\nExample 5\n\n\n\nGerman : Ein Kind in einer roten Jacke winkt mit einer Hand während es neben einem Plastikschlitten im Schnee liegt.\n\nEnglish : A child in a red coat waves a hand in the air while lying in snow beside a red plastic sled.\n\n\n\nEnglish Translations generated:\n\n\n\na child in a red jacket is laying next to a snow structure while holding a hand . \n\na child in a red jacket is laying next to a snow structure while holding a snow shovel . \n\na child in a red jacket is laying next to a snow structure while holding a plastic jacket . \n\n---------------------------------------------------------------------\n\n\n"
        }
      ],
      "id": "Zk_eX0_DIVe_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating Bleu Score"
      ],
      "metadata": {
        "papermill": {
          "duration": 3.484659,
          "end_time": "2023-10-11T19:46:45.479055",
          "exception": false,
          "start_time": "2023-10-11T19:46:41.994396",
          "status": "completed"
        },
        "tags": [],
        "id": "cu46pt5aIVe_"
      },
      "id": "cu46pt5aIVe_"
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu(data, model, device, max_len=50):\n",
        "    tgts = []\n",
        "    preds = []\n",
        "    for datum in tqdm(data):\n",
        "        src = datum[\"de\"]\n",
        "        tgt = datum[\"en\"]\n",
        "        src_idx = torch.tensor(text_transform_ger(src)).unsqueeze(0).to(device)\n",
        "        pred_tgt = translate_seq(model, src_idx, device, max_len)\n",
        "        pred_tgt = pred_tgt[1:-1]\n",
        "        pred_sent = [eng_vocab.get_itos()[i] for i in pred_tgt]\n",
        "        preds.append(pred_sent)\n",
        "        tgts.append([tokenizer_eng(tgt.lower())])\n",
        "\n",
        "    return bleu_score(preds, tgts)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:46:52.361497Z",
          "iopub.status.busy": "2023-10-11T19:46:52.361158Z",
          "iopub.status.idle": "2023-10-11T19:46:52.367198Z",
          "shell.execute_reply": "2023-10-11T19:46:52.366241Z"
        },
        "papermill": {
          "duration": 3.580643,
          "end_time": "2023-10-11T19:46:52.369081",
          "exception": false,
          "start_time": "2023-10-11T19:46:48.788438",
          "status": "completed"
        },
        "tags": [],
        "id": "XOqCOsUxIVe_"
      },
      "execution_count": null,
      "outputs": [],
      "id": "XOqCOsUxIVe_"
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = calculate_bleu(test, transformer_model, device)\n",
        "print(\"BLEU Score Achieved :\", bleu)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T19:46:59.873264Z",
          "iopub.status.busy": "2023-10-11T19:46:59.872936Z",
          "iopub.status.idle": "2023-10-11T19:48:35.648172Z",
          "shell.execute_reply": "2023-10-11T19:48:35.647058Z"
        },
        "papermill": {
          "duration": 99.149086,
          "end_time": "2023-10-11T19:48:35.650046",
          "exception": false,
          "start_time": "2023-10-11T19:46:56.500960",
          "status": "completed"
        },
        "tags": [],
        "id": "oCHpdRw1IVe_",
        "outputId": "a8341a44-ea09-4efa-d66c-a5457c21e500"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "100%|██████████| 1000/1000 [01:35<00:00, 10.48it/s]\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "BLEU Score Achieved : 0.30033090710639954\n"
        }
      ],
      "id": "oCHpdRw1IVe_"
    }
  ]
}